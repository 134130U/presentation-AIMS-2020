{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy: A look at the past, present, and future of array computation\n",
    "\n",
    "Ross Barnowski `rossbar@berkeley.edu` | [rossbar](https://github.com/rossbar) on GitHub\n",
    "\n",
    "University of Michigan EECS | 1/30/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is NumPy?\n",
    "\n",
    "> *NumPy is the fundamental package for scientific computing with Python*\n",
    "> \n",
    ">  [numpy.org](https://numpy.org/)\n",
    "\n",
    "Strong stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code example: github graphql query for top starred projects with numpy as a dependency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A bit of history\n",
    "\n",
    " - **Mid 90's/Early 00's**: desire for high-performance numerical computation in python leads to [`numeric`](https://numpy.org/_downloads/768fa66c250a0335ad3a6a30fae48e34/numeric-manual.pdf)\n",
    " - Early adopters included the [Space Telescope Science Institute (STScI)](http://www.stsci.edu/) who developed another array computation package to better suit their needs: `numarray`.\n",
    " - **2005** The best ideas from `numeric` and `numarray` were combined in the development of a new library, `numpy`\n",
    "   * This work was largely done by Travis Oliphant, then an assistant professor at BYU\n",
    " - **2006** Numpy v1.0 released\n",
    " \n",
    "[NumPy Development History](https://github.com/numpy/numpy/graphs/contributors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does NumPy provide?\n",
    "\n",
    " - `ndarray`: A generic, n-dimensional array data structure\n",
    " - Sophisticated machinery for operating on array data (broadcasting, `ufuncs`)\n",
    " - Tools for common scientific/numerical tasks:\n",
    "   * Random number generation (`np.random`)\n",
    "   * Fourier analysis (`np.fft`)\n",
    "   * Linear algebra (`np.linalg`)\n",
    " - Language extension/integration (C-API, `f2py`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where is NumPy used?\n",
    "\n",
    "### <font color=red> Investigate the following for appropriately sized examples </font>\n",
    "\n",
    " - To produce the first image of a black hole \n",
    "   [Event Horizon Telescope Collaboration](https://github.com/achael/eht-imaging)\n",
    " - [To detect the gravitational wave signature from a neutron star merger](https://github.com/gwastro/pycbc)\n",
    " - [To discover fundamental particles like the Higgs Boson](https://github.com/cms-sw/cmssw)\n",
    "   * Also [scikit-hep](https://scikit-hep.org/)\n",
    " - [Neuroimaging](https://nipy.org/nibabel/) - nipy uses `ndarray` as the fundamental structure for the entire stack\n",
    "   * fMRI visualization example from [section 3.4](https://www.frontiersin.org/articles/10.3389/fninf.2014.00014/full#h4)\n",
    "     is a nice, brief example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuroimaging Analysis\n",
    "\n",
    "Like much of the scientific python ecosystem, the [nipy organization](https://nipy.org/) relies on `np.ndarray` as the fundamental structure for neuroimaging data\n",
    "\n",
    "The following example is adapted from [Machine learning for neuroimaging with scikit learn](https://www.frontiersin.org/articles/10.3389/fninf.2014.00014/full). The dataset used comes from the [nilearn data](https://www.nitrc.org/frs/?group_id=728).\n",
    "\n",
    "<font color=red>**Add example of loading full Nifti image to show 4D structure of data?**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel   # package for loading/saving neuroimaging data\n",
    "bg_img = nibabel.load('data/bg.nii.gz')\n",
    "bg = bg_img.get_fdata()\n",
    "type(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create activation map by thresholding the data\n",
    "act_thresh = 6000\n",
    "act = bg.copy()\n",
    "# Set \"unactivated\" voxels to NaN for visualization\n",
    "act[act <= act_thresh] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set \"unactivated\" voxels to NaN for visualization\n",
    "\n",
    "imshow_opts = {\n",
    "    \"origin\" : \"lower\",\n",
    "    \"interpolation\" : \"nearest\"\n",
    "}\n",
    "\n",
    "# Axial slice of activation map overlay\n",
    "plt.imshow(bg[...,10].T, cmap=\"gray\");             # Background\n",
    "plt.imshow(act[...,10].T, cmap=\"plasma\");   # Activation map\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting gravitational wave signature of black hole and neutron star mergers\n",
    "\n",
    "[PyCBC](https://pycbc.org/) is the toolkit used to analyze data from gravitational wave observatories like [LIGO](https://www.ligo.caltech.edu/) and [Virgo](http://www.virgo-gw.eu/).\n",
    "\n",
    "The [PyCBC tutorials](https://github.com/gwastro/PyCBC-Tutorials) have some really cool examples - let's recreate the \"chirp\" from [first ever direct detection of gravitational waves](https://en.wikipedia.org/wiki/First_observation_of_gravitational_waves) that resulted from two black holes merging. For more info, see [the second PyCBC tutorial](https://colab.research.google.com/github/gwastro/pycbc-tutorials/blob/master/tutorial/2_VisualizationSignalProcessing.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycbc\n",
    "from pycbc import catalog\n",
    "\n",
    "merger_data = catalog.Merger('GW150914')\n",
    "# Though the catalog includes data from multiple observatories,\n",
    "# let's focus on just one\n",
    "ligo_data = merger_data.strain('L1')\n",
    "type(ligo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyCBC has it's own (quite extensive) API that uses\n",
    "# numpy & scipy under the hood\n",
    "print(type(ligo_data._data))\n",
    "pycbc.types.aligned.ArrayWithAligned.__bases__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To re-create the \"chirp\" we have to do some analysis on the raw data. `pycbc` relies on tools in `scipy.fft` and `scipy.signal` to implement the frequency analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten frequency \n",
    "res = ligo_data.whiten(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_of_merger = merger_data.time\n",
    "\n",
    "# Look 1-seconds worth of data around the merger time\n",
    "roi = res.time_slice(time_of_merger - 0.3, time_of_merger + 0.3)\n",
    "\n",
    "# Plot the spectrogram\n",
    "times, freqs, power = roi.qtransform(\n",
    "    delta_t=0.001,\n",
    "    logfsteps=100,\n",
    "    qrange=(8, 8),\n",
    "    frange=(30, 512),\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,3))\n",
    "ax.pcolormesh(times, freqs, power**0.5)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scope of NumPy\n",
    "\n",
    "NumPy currently targets computation involving:\n",
    "\n",
    " * in-memory, homogenously-typed array data\n",
    " * cpu-based\n",
    " \n",
    "Important guiding principles:\n",
    " - **Stability**: Foundational component of the scientific python ecosystem for going-on 15 years\n",
    " - **Interoperability**: A *de facto* standard for array APIs in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The changing landscape\n",
    "\n",
    " - In the early days, many new NumPy users were converts from matlab\n",
    "   * See the [NumPy for Matlab users](https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html) article in the docs\n",
    "   \n",
    " - Now: The scientific ecosystem is incredibly feature-rich and powerful: attracts many new users\n",
    "   * Users interested in specific applications (machine learning, image processing, geoscience, bioinformatics, etc.) end up interacting with NumPy indirectly\n",
    "   * Focus resources on supporting stable, performant base for dependent libraries\n",
    "     * Why scope is important: what goes in NumPy itself vs. dependent packages?\n",
    "     * Balance between performance and maintainability\n",
    "       > Optimization is the altar where maintainability is sacrificed\n",
    "       >\n",
    "       > L. Ramalho, *Fluent Python*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_dtype = np.dtype([\n",
    "    ('date', 'datetime64[M]'),\n",
    "    ('relpop', float)\n",
    "])\n",
    "\n",
    "parse_kwargs = {\n",
    "    \"skiprows\" : 3,\n",
    "    \"delimiter\" : \",\",\n",
    "    \"dtype\" : timeseries_dtype\n",
    "}\n",
    "\n",
    "gtrends_search_terms = (\"NumPy\", \"Data Science\", \"Matlab\")\n",
    "fnames = [name.lower().replace(' ', '') for name in gtrends_search_terms]\n",
    "\n",
    "data = {\n",
    "    fname : np.loadtxt(\"data/{}.csv\".format(fname), **parse_kwargs) for fname in fnames\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for name, vals in data.items():\n",
    "    plt.plot(vals['date'], vals['relpop'], label=name)\n",
    "ax.set_title('Google Trends (US): 2004 - Present')\n",
    "ax.set_ylabel('Relative Popularity of Search Term [arb]')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(s, kernsize=21):\n",
    "    s_padded = np.r_[s[kernsize-1:0:-1], s, s[-2:-kernsize-1:-1]]\n",
    "    kern = np.hamming(kernsize)\n",
    "    res_padded = np.convolve(kern/kern.sum(), s_padded, mode='valid')\n",
    "    # De-pad and renormalize\n",
    "    return res_padded[kernsize//2:-kernsize//2+1] / res_padded.max()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for name, vals in data.items():\n",
    "    plt.plot(vals['date'], smooth(vals['relpop']), label=name)\n",
    "ax.set_title('Google Trends (US): 2004 - Present')\n",
    "ax.set_ylabel('Relative Popularity of Search Term [arb]')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How is NumPy Developed\n",
    "\n",
    " - Collaboratively (caveat here about the bus factor)\n",
    "\n",
    "Commitment to stability means proposed changes must go through extensive design and review:\n",
    " - [NEPs](https://numpy.org/neps/) - analogous to PEPs, specific to NumPy\n",
    " - Steering council for high-level direction and coordination with [NumFOCUS](https://numfocus.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case-Study: `np.random`\n",
    "\n",
    " - Overhaul of `np.random` landed in version 1.17\n",
    " \n",
    "   * Improve *performance* and *flexibility* without sacrificing stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1,000,000 random numbers the old way\n",
    "old_rands = np.random.random(int(1e6))\n",
    "print(\"Uniform random numbers from legacy np.random.random:\\n  {}\".format(old_rands))\n",
    "\n",
    "# ... and the new way\n",
    "from numpy.random import PCG64, Generator\n",
    "rg = Generator(PCG64())\n",
    "new_rands = rg.random(int(1e6))\n",
    "print(\"Uniform random numbers with new tools:\\n  {}\".format(new_rands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compatibility\n",
    "\n",
    "Before version 1.17, `numpy.random` relied on `RandomState` to configure and produce random numbers.\n",
    "\n",
    "There are many, many LOC (both in test suites and in production) that depend on the original `numpy.random`, so both the *interface* and the *implementation* must remain unchanged\n",
    " * <font color=\"green\">**Upside:**</font> output of `np.random` remains \"stable\"\n",
    " * <font color=\"orange\">**Downside:**</font> users know about new interface to access improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a seed for generator\n",
    "seed = 1817\n",
    "\n",
    "# Random numbers generated by np.random in v1.15\n",
    "rands_from_v1_15 = np.load('data/npy_v1.15_random_seed1817_1000samples.npy')\n",
    "# Generate random numbers with legacy interface\n",
    "np.random.seed(seed)\n",
    "legacy_rands = np.random.random(1000)\n",
    "\n",
    "print(\"Arrays equivalent: \", np.allclose(rands_from_v1_15, legacy_rands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is possible (though clunky) to replicate legacy behavior with new interface\n",
    "seed = 1817\n",
    "\n",
    "from numpy.random import MT19937, RandomState\n",
    "# Set random state with legacy seeding\n",
    "rs = RandomState(seed)\n",
    "mt = MT19937()\n",
    "mt.state = rs.get_state()\n",
    "\n",
    "# New interface for generation\n",
    "mt_gen = Generator(mt)\n",
    "mt_rands = mt_gen.random(1000)\n",
    "print(\"Arrays equivalent: \", np.allclose(legacy_rands, mt_rands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "`Generator` includes improved methods for drawing samples from distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: PCG64 is the new default bit_generator, so the following is equivalent to Generator(PCG64())\n",
    "from numpy.random import default_rng\n",
    "rg = default_rng()\n",
    "num_samples = int(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Standard Normal:\")\n",
    "%timeit np.random.standard_normal(num_samples)\n",
    "%timeit rg.standard_normal(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Standard Exponential:\")\n",
    "%timeit np.random.standard_exponential(num_samples)\n",
    "%timeit rg.standard_exponential(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Standard Gamma:\")\n",
    "shape_param = 3.0\n",
    "%timeit np.random.standard_gamma(shape_param, num_samples)\n",
    "%timeit rg.standard_gamma(shape_param, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's next for NumPy?\n",
    "\n",
    "![NumpyRoadmapGraphic](./images/numpy_roadmap_graphic.png)\n",
    "\n",
    "Image from [this PyData Amsterdam 2019 presentation](https://www.slideshare.net/RalfGommers/the-evolution-of-array-computing-in-python/14) by [Ralf Gommers](https://github.com/rgommers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide(s) on interop\n",
    "\n",
    " - Ralf's material from [here](https://www.slideshare.net/RalfGommers/pydata-nyc-whatsnew-numpyscipy-2019?next_slideshow=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide(s) on dtype work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide(s) on SIMD work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slides on indexing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide(s) on type annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And beyond?\n",
    "\n",
    "NumPy 2.0? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting involved\n",
    "\n",
    "Great opportunity to work on a project that is depended on by tens of millions of users (and counting)\n",
    "\n",
    "What can you do:\n",
    "\n",
    " 1. Contribute\n",
    " \n",
    "   - [GitHub Issues](https://github.com/numpy/numpy/issues) and [open PRs](https://github.com/numpy/numpy/pulls) are a great entry point\n",
    "     * If you want to get your hands dirty immediately, try starting with the [good first issue](https://github.com/numpy/numpy/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22) label\n",
    "     * For challenges with a greater scope, try the [Enhancement](https://github.com/numpy/numpy/labels/01%20-%20Enhancement) or [Wish List](https://github.com/numpy/numpy/labels/23%20-%20Wish%20List) labels\n",
    "   - Check out the discussion revolving around current and future [NEPs](https://numpy.org/neps/)\n",
    "   \n",
    "\n",
    " 2. Participate in the conversation\n",
    " \n",
    "  - [Numpy discussion mailing list](https://www.scipy.org/scipylib/mailing-lists.html)\n",
    "  - Numpy community meetings (links and cadence here)\n",
    "  - slack channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
